* [A Unified Neural Network Approach for Estimating Travel Time and Distance for a Taxi Trip](https://arxiv.org/pdf/1710.04350.pdf)

# NLP
## Machine Translation, Seq2Seq and Attention 
* [Sequence to sequence learning with neural networks](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. "Sequence to sequence learning with neural networks." Advances in neural information processing systems. 2014.

* [Sequence Transduction with Recurrent Neural Networks](www.cs.toronto.edu/~graves/icml_2012.pdf) Graves, A. (2012). Sequence Transduction with Recurrent Neural Networks.
* [Sequence Transduction with Recurrent Neural Networks Slides](https://www.cs.toronto.edu/~graves/seq_trans_slides.pdf)

* [Neural machine translation by jointly learning to align and translate](https://arxiv.org/pdf/1409.0473.pdf) Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473. (Original **sequence-to-sequence** + **attention** paper) [NTM Slides](http://www.roeeaharoni.com/NMT_slides.pdf)

* [Massive Exploration of Neural Machine Translation Architectures](http://www.aclweb.org/anthology/D17-1151) Britz, D., Goldie, A., Luong, M. T., & Le, Q. (2017). Massive Exploration of Neural Machine Translation Architectures. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 1442-1451).

## Word Segmentation
* [Adversarial multi-criteria learning for chinese word segmentation](http://www.aclweb.org/anthology/P17-1110) Chen, X., Shi, Z., Qiu, X., & Huang, X. (2017). Adversarial Multi-Criteria Learning for Chinese Word Segmentation. ACL (Vol. 1, pp. 1193-1203).

* [Neural Networks Incorporating Dictionaries for Chinese Word Segmentation](http://jkx.fudan.edu.cn/~qzhang/paper/aaai2017-cws.pdf) Zhang, Q., Liu, X., & Fu, J. (2018). Neural Networks Incorporating Dictionaries for Chinese Word Segmentation. AAAI 2018

## NMT
* [On using very large target vocabulary for neural machine translation](http://www.anthology.aclweb.org/P/P15/P15-1001.pdf) (Containing RNNSearch, RNNSearch-LV)

* [Neural machine translation of rare words with subword units](http://www.aclweb.org/anthology/P16-1162) (About BPE, Byte Pair Encoding)

* [A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation](http://anthology.aclweb.org/P/P16/P16-1160.pdf) (About BPE-Char)

* [Deep recurrent models with fast-forward connections for neural machine translation](http://www.aclweb.org/anthology/Q16-1027)(About Deep-Att)

* [Effective approaches to attention-based neural machine translation](http://www.aclweb.org/anthology/D15-1166)(About Luong)

* [A convolutional encoder model for neural machine translation](http://www.aclweb.org/anthology/P17-1012)(About Deep-Conv)

* [Google's neural machine translation system: Bridging the gap between human and machine translation](http://web.stanford.edu/class/psych209/Readings/WuEtAl16NeuralMachineTranslation.pdf)(About GNMT)

* [Opennmt: Open-source toolkit for neural machine translation](http://www.aclweb.org/anthology/P17-4012)(About OpenNMT)


# RNN
* [Bidirectional recurrent neural networks](http://www.cs.cmu.edu/afs/cs/user/bhiksha/WWW/courses/deeplearning/Fall.2016/pdfs/Schuster97_BRNN.pdf) 
Schuster, M., & Paliwal, K. K. (1997). **Bidirectional recurrent neural networks**. IEEE Transactions on Signal Processing, 45(11), 2673-2681.

* [Framewise phoneme classification with bidirectional LSTM and other neural network architectures](http://wwwknoll.informatik.tu-muenchen.de/pub/Main/Publications/Graves2005b.pdf) Graves, A., & Schmidhuber, J. (2005). Framewise phoneme classification with **bidirectional LSTM** and other neural network architectures. Neural Networks, 18(5-6), 602-610. 

# NTM
* [Neural turing machines](https://arxiv.org/pdf/1410.5401.pdf) Graves, A., Wayne, G., & Danihelka, I. (2014). Neural turing machines. arXiv preprint arXiv:1410.5401.

* [Reinforcement learning neural Turing machines](https://arxiv.org/pdf/1505.00521.pdf) Zaremba, W., & Sutskever, I. (2015). Reinforcement learning neural Turing machines.

# Attention
 * [Show, attend and tell: Neural image caption generation with visual attention](http://proceedings.mlr.press/v37/xuc15.pdf)
 Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., ... & Bengio, Y. (2015, June). Show, attend and tell: Neural image caption generation with visual attention. In International conference on machine learning (pp. 2048-2057).
 
 * [Learning Efficient Algorithms with Hierarchical Attentive Memory](https://pdfs.semanticscholar.org/2fca/50789703349f23dd5db3ee9dd20ad5cfc9d9.pdf) Andrychowicz, M., & Kurach, K. (2016). Learning Efficient Algorithms with Hierarchical Attentive Memory.
 
 * [A Deep Reinforced Model for Abstractive Summarization](https://arxiv.org/pdf/1705.04304.pdf)
 
 * [Get to the point: Summarization with pointer-generator networks](http://www.aclweb.org/anthology/P17-1099) See, A., Liu, P. J., & Manning, C. D. (2017). Get To The Point: Summarization with Pointer-Generator Networks. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (Vol. 1, pp. 1073-1083).
 
 * [Blackout: Speeding up recurrent neural network language models with very large vocabularies](https://arxiv.org/pdf/1511.06909.pdf) Ji, S., Vishwanathan, S. V. N., Satish, N., Anderson, M. J., & Dubey, P. (2015). Blackout: Speeding up recurrent neural network language models with very large vocabularies. arXiv preprint arXiv:1511.06909.

# HMM
* [Rejection strategies for offline handwritten text line recognition](http://www.xbrain.ch/d/2006_prl.pdf) Bertolami, R., Zimmermann, M., & Bunke, H. (2006). Rejection strategies for offline handwritten text line recognition. Pattern Recognition Letters, 27(16), 2005-2012.

# GO
* [Mastering the game of Go with deep neural networks and tree search](http://home.ustc.edu.cn/~ustcsh/py2016/data/nature16961.pdf) Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., ... & Dieleman, S. (2016). Mastering the game of Go with deep neural networks and tree search. nature, 529(7587), 484.


# Optimization
* [Adam: Amethod for stochastic optimization](https://arxiv.org/pdf/1412.6980.pdf) Kingma, Diederik P., and Jimmy Lei Ba. "**Adam**: Amethod for stochastic optimization." Proc. 3rd Int. Conf. Learn. Representations. 2014.

* [Gradient-based learning algorithms for recurrent networks and their computational complexity](https://pdfs.semanticscholar.org/cccd/3fd7a45e7643f26391bd539ffbede0690f36.pdf) Williams, R. J., & Zipser, D. (1995). Gradient-based learning algorithms for recurrent networks and their computational complexity. Backpropagation: Theory, architectures, and applications, 1, 433-486. (Mainly About **Backpropagation Through Time**)


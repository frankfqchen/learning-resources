# run spark jar
spark-submit --class com.chinapex.ctrip.churn.textReader --master local Collect-1.0-SNAPSHOT.jar

# spark hbase
* [spark将数据写入hbase以及从hbase读取数据](http://blog.csdn.net/u013468917/article/details/52822074)
* [using spark to read specific columns data from hbase](http://stackoverflow.com/questions/27122409/using-spark-to-read-specific-columns-data-from-hbase)
* [How to use HBase ColumnRangeFilter by Spark](https://stackoverflow.com/questions/42604507/how-to-use-hbase-columnrangefilter-by-spark)
* [hbase 异常 Server is not running yet](http://m.blog.csdn.net/article/details?id=53160577)

# spark sql
* [Upacking a list to select multiple columns from a spark data frame](http://stackoverflow.com/questions/34938770/upacking-a-list-to-select-multiple-columns-from-a-spark-data-frame)

# spark logistic regression
* [Spark LogisticRegression 逻辑回归之建模](http://www.cnblogs.com/wwxbi/p/6224670.html)
* [在Apache Spark上跑Logistic Regression算法](http://www.csdn.net/article/2015-07-24/2825285)

# spark kmeans
* [Spark KMeans clustering: get the number of sample assigned to a cluster](http://stackoverflow.com/questions/33495287/spark-kmeans-clustering-get-the-number-of-sample-assigned-to-a-cluster)

# spark dataframe
* [Convert Spark's DataFrame to RDD[Vector]](http://stackoverflow.com/questions/41712556/convert-sparks-dataframe-to-rddvector)

